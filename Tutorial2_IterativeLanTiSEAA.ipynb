{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Usage of IterativeLanTiSEAA\n",
    "\n",
    "The class lantiseaa.IterativeLanTiSEAA is a also classifier that can be integrated with the sklearn framework. It implements the Language Time Series Enriched Authorship Attribution method with the iterative stacking framework described in the paper. Hence, in the fit function of IterativeLanTiSEAA, the whole process from splitting folds to selecting a final combination of feature groups described in the paper was implemented. Just like LanTiSEAA, IterativeLanTiSEAA can take customized time series transformers, feature extractor, baseline classifier, meta classifier and buffer object. Besides, it can also take a specified cv (fold splitter) and a metric for evaluating the predictions on each fold. In the stacking process, like in the paper, both bayesian estimation and Wilcoxon Signed Rank Test were used to measure the effect of adding a feature group. After selecting the best combination, IterativeLanTiSEAA will be fit on the complete training data set and ready for predicting unseen testing data.\n",
    "\n",
    "Using a sample data set which contains 1% of the samples randomly selected from the Spooky Books Data Set described in the paper (while keeping the class distribution), this notebook shows an example of using IterativeLanTiSEAA to study a language time series enriched authorship attribution classification task.\n",
    "\n",
    "# Table of Content\n",
    "1. [Import Data](#1)\n",
    "2. [Split train and test data set](#2)\n",
    "3. [Use IterativeLanTiSEAA to study a language time series enriched authorship attribution classification task](#3) <br>\n",
    "3. [Another task with a bad baseline method](#3) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "sns.set()\n",
    "\n",
    "import lantiseaa\n",
    "import lantiseaa.ts as ts\n",
    "from lantiseaa import IterativeLanTiSEAA\n",
    "from lantiseaa.baseline import BOWMNB\n",
    "from lantiseaa.extractor import TsfreshTSFeatureExtractor\n",
    "from lantiseaa.buffer import LocalBuffer, MemoryBuffer\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LocalBuffer can be used as a project IO for reading and saving data. Here we use it to read the sample data set and save results produced during the execution. MemoryBuffer can also be used to save results (temporarily) on the computer memory, and it is the default buffer used for class LanTiSEAA. However, for research purposes, we want to save all the results on the disks and maybe look for usaful information later in the study. Hence, LocalBuffer is used in this tutorial.\n",
    "\n",
    "In default, LocalBuffer set the root project directory at one level beyound the module \"LanTiSEAA\" folder. E.g. if the folder \"LanTiSEAA\" is placed under a folder named \"my_project\", the \"my_project\" folder will be set as the project folder and all data will be read/saved from/to the \"my_project\" folder. We want to direct it to the place where we want it to be - in this case, the \"LanTiSEAA\" folder itself.\n",
    "\n",
    "Besides, in default, the subfolder which used to organize the data produced from this specific execution is not set. We want to specify a subfolder for better organization of the saved files, in this case - \"tutorial1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = LocalBuffer(project_path=os.getcwd(), subfolder='tutorial2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.subfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use LocalBuffer to get absolute paths to files in the project folder (note that path for a file that does not exist can be returned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.data(filename='sample_dataset.csv', subfolder='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.results(filename='somefile.hdf', subfolder='tutorial2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.figures(filename='somefig.png', subfolder='tutorial2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.classes(filename='someclass.pkl', subfolder='tutorial2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.project(filename='Tutorial2_IterativeLanTiSEAA.ipynb', folder='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use LocalMemory to read sample data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(io.data('sample_dataset.csv'))\n",
    "\n",
    "texts = dataset.text\n",
    "y = dataset.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the authors in the data set\n",
    "y_values = y.value_counts()\n",
    "\n",
    "sns.barplot(y_values.index, y_values.values, alpha=0.8)\n",
    "plt.title('Distribution of authors in sample data set')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel(\"Author\", fontsize=12)\n",
    "plt.show() # distribution is kept the same as the original data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split train and test data set <a class=\"anchor\" id=\"2\"></a>\n",
    "Leave about 1/3 of the data as the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = texts_train.reset_index(drop=True)\n",
    "texts_test = texts_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use IterativeLanTiSEAA to study a language time series enriched authorship attribution classification task <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar with LanTiSEAA, IterativeLanTiSEAA can also take in custmizable objects and parameters. Beyound those in LanTiSEAA, IterativeLanTiSEAA can also take in a cv for splitting folders, a metric to evaluate the predictions made on folds, and a random_state which specifies the random seed to use when using StratifiedKFold to split folds if the cv parameter is an integer or None. The greater_is_better parameter specifies that either are the scores obtained by the metric better if they are higher or lower.\n",
    "\n",
    "In this notebook, again we simply use the defaults, except a few changes. \n",
    "\n",
    "Besides the same changes been made on LanTiSEAA in tutorial 1, we also want to make the fdr_levels for bayesian estimation and wilcoxon signed rank test to be higher.\n",
    "\n",
    "However, with such a small data set that has very little information for classification but a lot of noises, neither the baseline method nor the time series features enriched one can handle it. Especially because Gradient Boosting meta classifier is noise-sensitive, we are expecting the time series features to reduce the performance of the baseline method because they will contain mainly noises. In the end, the baseline method will be chosen as a single best classifier.\n",
    "\n",
    "To show how the IterativeLanTiSEAA manages with stacking time series features that improves the baseline method, in [section 4](#4) we will generate a very bad baseline and let the time series features improve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_classifier = XGBClassifier(objective='multi:softprob', num_class=3, n_jobs=-1, nthread=-1)\n",
    "feature_extractor=TsfreshTSFeatureExtractor(fdr_level=15)\n",
    "clf = IterativeLanTiSEAA(ts_transformers=[ts.TokenLenSeqTransformer(), \n",
    "                                          ts.TokenFreqSeqTransformer(), \n",
    "                                          ts.TokenRankSeqTransformer(), \n",
    "                                          ts.TokenLenDistTransformer()], \n",
    "                         feature_extractor=feature_extractor, meta_classifier=meta_classifier, buffer=io)\n",
    "clf.fit(texts_train, y_train, fdr_level_bayesian=0.5, fdr_level_wilcoxon=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.relevant_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_groups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.read_evaluation_score('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "io.read_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Another task with a bad baseline method <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how IterativeLanTiSEAA manage with stacking time series features to improve baseline, in this task, we introduce a very bad baseline prediction that made all predictions wrong - and see how time series features improved it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_baseline_predictions_train = []\n",
    "bad_labels = []\n",
    "for label in y_train:\n",
    "    new_label = label\n",
    "    while new_label == label:\n",
    "        new_label = random.choice(['EAP', 'MWS', 'HPL'])\n",
    "    bad_labels.append(new_label)\n",
    "    \n",
    "lb = LabelBinarizer()\n",
    "lb.fit(bad_labels)\n",
    "bad_baseline_predictions_train = pd.DataFrame(lb.transform(bad_labels), columns=lb.classes_)\n",
    "bad_baseline_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io2 = LocalBuffer(project_path=os.getcwd(), subfolder='tutorial2_task2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_classifier = XGBClassifier(objective='multi:softprob', num_class=3, n_jobs=-1, nthread=-1)\n",
    "feature_extractor=TsfreshTSFeatureExtractor(fdr_level=15)\n",
    "clf = IterativeLanTiSEAA(ts_transformers=[ts.TokenLenSeqTransformer(), \n",
    "                                          ts.TokenFreqSeqTransformer(), \n",
    "                                          ts.TokenRankSeqTransformer(), \n",
    "                                          ts.TokenLenDistTransformer()], \n",
    "                         baseline_classifier=None,\n",
    "                         feature_extractor=feature_extractor, meta_classifier=meta_classifier, buffer=io2)\n",
    "clf.fit(texts_train, y_train, fdr_level_bayesian=0.5, fdr_level_wilcoxon=0.5, \n",
    "        baseline_prediction=bad_baseline_predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.relevant_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_groups_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature_groups_ attribute after fitting shows the best combination of the feature groups. In this case, Token Frequency Sequence was the single time series feature group that improved the predictions the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io2.read_evaluation_score('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io2.read_evaluation_score('baseline_tokenfreqseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = io2.read_bayesian_estimation_trace(\"baseline\", \"baseline_tokenfreqseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['difference of means'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "io2.read_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
